{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code based on https://gist.githubusercontent.com/AFAgarap/92c1c4a5dd771999b0201ec0e7edfee0/raw/828fbda0e466dacb1fad66549e0e3022e1c7263a/gru_svm_zalando_dropout.py by Abien Fred Agarap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('data/fashion', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = 'models/'\n",
    "MODEL_NAME = 'model19' + str(time.asctime()) +'.ckpt'\n",
    "LOGS_PATH = 'logs/'\n",
    "RESTORE_CKP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 1024\n",
    "EV_BATCH_SIZE = 10000\n",
    "CELL_SIZE = 256\n",
    "DROPOUT_P_KEEP = 0.55\n",
    "NUM_CLASSES = 10\n",
    "SVM_C = 1\n",
    "\n",
    "# dataset dimension\n",
    "CHUNK_SIZE = 28\n",
    "NUM_CHUNKS = 28\n",
    "\n",
    "# learning rate dacay parameters\n",
    "INITIAL_LEARNING_RATE = 1e-3\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.995\n",
    "NUM_EPOCHS_PER_DECAY = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None, NUM_CHUNKS, CHUNK_SIZE], name='x_input')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, NUM_CLASSES], name='y_input')\n",
    "h = tf.placeholder(dtype=tf.float32, shape=[None, CELL_SIZE], name='state')\n",
    "\n",
    "learning_rate = tf.placeholder(dtype=tf.float32, name='learning_rate')\n",
    "p_keep = tf.placeholder(dtype=tf.float32, name='p_keep')\n",
    "\n",
    "# evaluation placeholders\n",
    "ev_x = tf.placeholder(dtype=tf.float32, shape=[None, NUM_CHUNKS, CHUNK_SIZE], name='x_input')\n",
    "ev_y = tf.placeholder(dtype=tf.float32, shape=[None, NUM_CLASSES], name='y_input')\n",
    "ev_value = tf.placeholder(dtype=tf.float32, name=\"ev_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recurrent_neural_network(x):\n",
    "    with tf.name_scope('weights_and_biases'):\n",
    "        with tf.name_scope('weights'):\n",
    "            xav_init = tf.contrib.layers.xavier_initializer\n",
    "            weight_2 = tf.get_variable('weights_2', shape=[CELL_SIZE, NUM_CLASSES], initializer=xav_init())\n",
    "            variable_summaries(weight_2)\n",
    "        with tf.name_scope('biases'):\n",
    "            bias_2 = tf.get_variable('biases_2', initializer=tf.constant(0.1, shape=[NUM_CLASSES]))\n",
    "            variable_summaries(bias_2)\n",
    "\n",
    "    cell = tf.contrib.rnn.GRUCell(CELL_SIZE)\n",
    "    drop_cell = tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=p_keep, output_keep_prob=p_keep)\n",
    "\n",
    "    outputs, states = tf.nn.dynamic_rnn(drop_cell, x, initial_state=h, dtype=tf.float32)\n",
    "\n",
    "    states = tf.identity(states, name='H')\n",
    "    hf = tf.transpose(outputs, [1, 0, 2])\n",
    "    last = tf.gather(hf, int(hf.get_shape()[0]) - 1)\n",
    "\n",
    "    with tf.name_scope('Wx_plus_b'):\n",
    "        output = tf.matmul(last, weight_2) + bias_2\n",
    "        tf.summary.histogram('pre-activations', output)\n",
    "    return output, weight_2, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(x):\n",
    "    # Decay the learning rate exponentially based on the number of steps.\n",
    "    # gstep is just a placeholder for epoch number, that will trigger decay of lr\n",
    "    gstep = tf.placeholder(dtype=tf.float32, shape=[], name=\"global_step\")\n",
    "    learning_rate = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                                gstep,\n",
    "                                                NUM_EPOCHS_PER_DECAY,\n",
    "                                                LEARNING_RATE_DECAY_FACTOR,\n",
    "                                                staircase=True, name='learning_rate')    \n",
    "   \n",
    "    prediction, weight, states = recurrent_neural_network(x)\n",
    "\n",
    "    # Add a summary to track the learning rate.\n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        regularization_loss = 0.5 * tf.reduce_sum(tf.square(weight)) #+ 0.5 * tf.reduce_sum(tf.square(maxout_weight))\n",
    "        hinge_loss = tf.reduce_sum(tf.square(tf.maximum(tf.zeros([BATCH_SIZE, NUM_CLASSES]),\n",
    "                                                        1 - tf.cast(y, tf.float32) * prediction)))\n",
    "        with tf.name_scope('loss'):\n",
    "            cost = regularization_loss + SVM_C * hinge_loss\n",
    "    tf.summary.scalar('loss', cost)\n",
    "    \n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        predicted_class = tf.sign(prediction)\n",
    "        predicted_class = tf.identity(predicted_class, name='prediction')\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            correct = tf.equal(tf.argmax(predicted_class, 1), tf.argmax(y, 1))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    # merge is before ev_summary_op, because we want evaluation to be in a separate op\n",
    "    # otherwise we will double log the predictions from train set\n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.name_scope('evaluation'):\n",
    "        ev_predicted_class = tf.sign(prediction)\n",
    "        ev_predicted_class = tf.identity(ev_predicted_class, name='prediction')\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            ev_correct = tf.equal(tf.argmax(ev_predicted_class, 1), tf.argmax(y, 1))\n",
    "        with tf.name_scope('evaluation'):\n",
    "            evaluation = tf.reduce_mean(tf.cast(ev_correct, 'float'))\n",
    "    ev_summary_op = tf.summary.scalar(\"evaluation\", ev_value)\n",
    "    \n",
    "\n",
    "    timestamp = str(time.asctime())\n",
    "    train_writer = tf.summary.FileWriter(LOGS_PATH + timestamp, graph=tf.get_default_graph())\n",
    "    saver = tf.train.Saver(max_to_keep=10)\n",
    "\n",
    "    current_state = np.zeros([BATCH_SIZE, CELL_SIZE])\n",
    "\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "\n",
    "        checkpoint = tf.train.get_checkpoint_state(CHECKPOINT_PATH)\n",
    "\n",
    "        if checkpoint and checkpoint.model_checkpoint_path and RESTORE_CKP:\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(CHECKPOINT_PATH))\n",
    "            pass\n",
    "        try:\n",
    "            for epoch in range(EPOCHS):\n",
    "                \n",
    "                epoch_loss = 0\n",
    "                for _ in range(int(data.train.num_examples / BATCH_SIZE)):\n",
    "                    epoch_x, epoch_y = data.train.next_batch(BATCH_SIZE)\n",
    "                    \n",
    "                    epoch_y[epoch_y == 0] = -1\n",
    "\n",
    "                    epoch_x =  epoch_x.reshape((BATCH_SIZE, NUM_CHUNKS, CHUNK_SIZE))\n",
    "                    \n",
    "\n",
    "                    feed_dict = {x: epoch_x, y: epoch_y, h: current_state,\n",
    "                                   gstep: epoch, p_keep:DROPOUT_P_KEEP}\n",
    "\n",
    "                    summary, lr, _, next_state, c, accuracy_ = sess.run([merged, learning_rate, optimizer, states, cost, accuracy],\n",
    "                                                                    feed_dict=feed_dict)\n",
    "                    epoch_loss = c\n",
    "                    current_state = next_state\n",
    "                    #\n",
    "                    # Real-time evaluation on test set\n",
    "                    #\n",
    "                    with tf.name_scope('evaluation'):\n",
    "                        ev_x_, ev_y_ = data.test.next_batch(EV_BATCH_SIZE) \n",
    "                        ev_x_ = ev_x_.reshape((-1, NUM_CHUNKS, CHUNK_SIZE))\n",
    "                        ev_y_[ev_y_ == 0] = -1\n",
    "\n",
    "                        ev_accuracy_ = sess.run(evaluation, feed_dict={x: ev_x_, y: ev_y_,\n",
    "                                                      h: np.zeros([EV_BATCH_SIZE, CELL_SIZE]),\n",
    "                                                      p_keep: 1.0})\n",
    "                        ev_summary_op_ = sess.run(ev_summary_op, feed_dict={ev_value: ev_accuracy_})\n",
    "                \n",
    "                if epoch % 2 == 0:\n",
    "                    saver.save(sess, CHECKPOINT_PATH + MODEL_NAME, global_step=epoch)\n",
    "                train_writer.add_summary(summary, epoch)\n",
    "                train_writer.add_summary(ev_summary_op_, epoch)\n",
    "                print('Epoch : {} completed out of {}, loss : {}, accuracy : {}, acc2: {}'.format(epoch, EPOCHS,\n",
    "                                                                                        epoch_loss, accuracy_, ev_accuracy_))\n",
    "        except KeyboardInterrupt:\n",
    "            print('Training interrupted at {}'.format(epoch))\n",
    "        finally:\n",
    "            train_writer.close()\n",
    "\n",
    "        saver.save(sess, CHECKPOINT_PATH + MODEL_NAME, global_step=epoch)\n",
    "\n",
    "        x_ = data.test.images.reshape((-1, NUM_CHUNKS, CHUNK_SIZE))\n",
    "        y_ = data.test.labels\n",
    "        y_[y_ == 0] = -1\n",
    "\n",
    "        accuracy_ = sess.run(accuracy, feed_dict={x: x_, y: y_,\n",
    "                                                  h: np.zeros([10000, CELL_SIZE]),\n",
    "                                                  p_keep: 1.0})\n",
    "\n",
    "        print('Accuracy : {}'.format(accuracy_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 completed out of 100, loss : 2817.30517578125, accuracy : 0.283203125, acc2: 0.34899991750717163\n",
      "Epoch : 1 completed out of 100, loss : 1431.6405029296875, accuracy : 0.67578125, acc2: 0.8008000254631042\n",
      "Epoch : 2 completed out of 100, loss : 1015.3193359375, accuracy : 0.8046875, acc2: 0.897800087928772\n",
      "Epoch : 3 completed out of 100, loss : 743.4059448242188, accuracy : 0.865234375, acc2: 0.9122000932693481\n",
      "Epoch : 4 completed out of 100, loss : 553.884033203125, accuracy : 0.908203125, acc2: 0.93340003490448\n",
      "Epoch : 5 completed out of 100, loss : 389.5703430175781, accuracy : 0.9384765625, acc2: 0.9441001415252686\n",
      "Epoch : 6 completed out of 100, loss : 358.37115478515625, accuracy : 0.9453125, acc2: 0.9532001614570618\n",
      "Epoch : 7 completed out of 100, loss : 303.1078796386719, accuracy : 0.9462890625, acc2: 0.9571000933647156\n",
      "Epoch : 8 completed out of 100, loss : 337.7618103027344, accuracy : 0.94921875, acc2: 0.9571001529693604\n",
      "Epoch : 9 completed out of 100, loss : 266.2430114746094, accuracy : 0.9453125, acc2: 0.9645001292228699\n",
      "Epoch : 10 completed out of 100, loss : 366.11859130859375, accuracy : 0.935546875, acc2: 0.9655001163482666\n",
      "Epoch : 11 completed out of 100, loss : 281.27911376953125, accuracy : 0.962890625, acc2: 0.9686000943183899\n",
      "Epoch : 12 completed out of 100, loss : 267.2800598144531, accuracy : 0.9443359375, acc2: 0.9683001637458801\n",
      "Epoch : 13 completed out of 100, loss : 256.44091796875, accuracy : 0.9560546875, acc2: 0.9684001803398132\n",
      "Epoch : 14 completed out of 100, loss : 220.7013397216797, accuracy : 0.9638671875, acc2: 0.9729000926017761\n",
      "Epoch : 15 completed out of 100, loss : 210.85569763183594, accuracy : 0.9609375, acc2: 0.9752001166343689\n",
      "Epoch : 16 completed out of 100, loss : 148.8978729248047, accuracy : 0.9755859375, acc2: 0.9738001227378845\n",
      "Epoch : 17 completed out of 100, loss : 162.47409057617188, accuracy : 0.9697265625, acc2: 0.9719001054763794\n",
      "Epoch : 18 completed out of 100, loss : 206.01763916015625, accuracy : 0.966796875, acc2: 0.9767000675201416\n",
      "Epoch : 19 completed out of 100, loss : 176.80723571777344, accuracy : 0.9677734375, acc2: 0.9779001474380493\n",
      "Epoch : 20 completed out of 100, loss : 182.00949096679688, accuracy : 0.970703125, acc2: 0.9785001277923584\n",
      "Epoch : 21 completed out of 100, loss : 160.86151123046875, accuracy : 0.9697265625, acc2: 0.9773001074790955\n",
      "Epoch : 22 completed out of 100, loss : 146.96580505371094, accuracy : 0.98046875, acc2: 0.9784001708030701\n",
      "Epoch : 23 completed out of 100, loss : 206.8118896484375, accuracy : 0.9638671875, acc2: 0.9788000583648682\n",
      "Epoch : 24 completed out of 100, loss : 144.2568817138672, accuracy : 0.978515625, acc2: 0.9795001149177551\n",
      "Epoch : 25 completed out of 100, loss : 160.2708282470703, accuracy : 0.9697265625, acc2: 0.9798001646995544\n",
      "Epoch : 26 completed out of 100, loss : 158.59315490722656, accuracy : 0.9716796875, acc2: 0.9797000885009766\n",
      "Epoch : 27 completed out of 100, loss : 123.09197235107422, accuracy : 0.98046875, acc2: 0.9809001088142395\n",
      "Epoch : 28 completed out of 100, loss : 131.87525939941406, accuracy : 0.9755859375, acc2: 0.9817001223564148\n",
      "Epoch : 29 completed out of 100, loss : 123.48980712890625, accuracy : 0.978515625, acc2: 0.9821001291275024\n",
      "Epoch : 30 completed out of 100, loss : 146.92477416992188, accuracy : 0.9794921875, acc2: 0.9825001358985901\n",
      "Epoch : 31 completed out of 100, loss : 130.09739685058594, accuracy : 0.978515625, acc2: 0.9822000861167908\n",
      "Epoch : 32 completed out of 100, loss : 83.20121002197266, accuracy : 0.986328125, acc2: 0.9818000793457031\n",
      "Epoch : 33 completed out of 100, loss : 122.42462921142578, accuracy : 0.978515625, acc2: 0.9834000468254089\n",
      "Epoch : 34 completed out of 100, loss : 138.1147918701172, accuracy : 0.98046875, acc2: 0.9831001162528992\n",
      "Epoch : 35 completed out of 100, loss : 120.1305923461914, accuracy : 0.978515625, acc2: 0.9841001033782959\n",
      "Epoch : 36 completed out of 100, loss : 125.53596496582031, accuracy : 0.984375, acc2: 0.9838001132011414\n",
      "Epoch : 37 completed out of 100, loss : 90.30162048339844, accuracy : 0.982421875, acc2: 0.9838001728057861\n",
      "Epoch : 38 completed out of 100, loss : 136.7836151123047, accuracy : 0.9814453125, acc2: 0.9825001358985901\n",
      "Epoch : 39 completed out of 100, loss : 133.5214385986328, accuracy : 0.974609375, acc2: 0.9821001887321472\n",
      "Epoch : 40 completed out of 100, loss : 149.19654846191406, accuracy : 0.982421875, acc2: 0.9810001850128174\n",
      "Epoch : 41 completed out of 100, loss : 82.80902099609375, accuracy : 0.9892578125, acc2: 0.9847001433372498\n",
      "Epoch : 42 completed out of 100, loss : 101.67819213867188, accuracy : 0.982421875, acc2: 0.9849001169204712\n",
      "Epoch : 43 completed out of 100, loss : 92.60283660888672, accuracy : 0.98046875, acc2: 0.9843001961708069\n",
      "Epoch : 44 completed out of 100, loss : 100.63255310058594, accuracy : 0.984375, acc2: 0.9819000959396362\n",
      "Epoch : 45 completed out of 100, loss : 77.78446197509766, accuracy : 0.9853515625, acc2: 0.9836001396179199\n",
      "Epoch : 46 completed out of 100, loss : 129.21957397460938, accuracy : 0.9755859375, acc2: 0.9839001297950745\n",
      "Epoch : 47 completed out of 100, loss : 113.30805969238281, accuracy : 0.9853515625, acc2: 0.9853000640869141\n",
      "Epoch : 48 completed out of 100, loss : 117.28495025634766, accuracy : 0.982421875, acc2: 0.9841001033782959\n",
      "Epoch : 49 completed out of 100, loss : 95.85733032226562, accuracy : 0.986328125, acc2: 0.9852001667022705\n",
      "Epoch : 50 completed out of 100, loss : 93.47056579589844, accuracy : 0.9814453125, acc2: 0.9828001856803894\n",
      "Epoch : 51 completed out of 100, loss : 94.11360168457031, accuracy : 0.98828125, acc2: 0.9844001531600952\n",
      "Epoch : 52 completed out of 100, loss : 96.0223159790039, accuracy : 0.984375, acc2: 0.9826000928878784\n",
      "Epoch : 53 completed out of 100, loss : 110.13822937011719, accuracy : 0.9794921875, acc2: 0.9836001396179199\n",
      "Epoch : 54 completed out of 100, loss : 76.07011413574219, accuracy : 0.990234375, acc2: 0.9841001033782959\n",
      "Epoch : 55 completed out of 100, loss : 107.61209869384766, accuracy : 0.978515625, acc2: 0.9827001094818115\n",
      "Epoch : 56 completed out of 100, loss : 82.35317993164062, accuracy : 0.990234375, acc2: 0.9834001064300537\n",
      "Epoch : 57 completed out of 100, loss : 74.94960021972656, accuracy : 0.9873046875, acc2: 0.983700156211853\n",
      "Epoch : 58 completed out of 100, loss : 65.07581329345703, accuracy : 0.9912109375, acc2: 0.9865001440048218\n",
      "Epoch : 59 completed out of 100, loss : 64.53302001953125, accuracy : 0.990234375, acc2: 0.9847001433372498\n",
      "Epoch : 60 completed out of 100, loss : 88.52462005615234, accuracy : 0.984375, acc2: 0.9849001169204712\n",
      "Epoch : 61 completed out of 100, loss : 61.82423400878906, accuracy : 0.9892578125, acc2: 0.984200119972229\n",
      "Epoch : 62 completed out of 100, loss : 75.53460693359375, accuracy : 0.9873046875, acc2: 0.9831001162528992\n",
      "Epoch : 63 completed out of 100, loss : 67.032958984375, accuracy : 0.984375, acc2: 0.9825000762939453\n",
      "Epoch : 64 completed out of 100, loss : 60.85901641845703, accuracy : 0.9921875, acc2: 0.9841001033782959\n",
      "Epoch : 65 completed out of 100, loss : 91.08653259277344, accuracy : 0.98828125, acc2: 0.9840000867843628\n",
      "Epoch : 66 completed out of 100, loss : 92.03567504882812, accuracy : 0.9833984375, acc2: 0.9836001396179199\n",
      "Epoch : 67 completed out of 100, loss : 70.79051971435547, accuracy : 0.98828125, acc2: 0.9850001335144043\n",
      "Epoch : 68 completed out of 100, loss : 60.147403717041016, accuracy : 0.9892578125, acc2: 0.9846001267433167\n",
      "Epoch : 69 completed out of 100, loss : 72.65484619140625, accuracy : 0.990234375, acc2: 0.9835001230239868\n",
      "Epoch : 70 completed out of 100, loss : 56.52252197265625, accuracy : 0.990234375, acc2: 0.9843000769615173\n",
      "Epoch : 71 completed out of 100, loss : 66.25932312011719, accuracy : 0.98828125, acc2: 0.9828000664710999\n",
      "Epoch : 72 completed out of 100, loss : 79.04338836669922, accuracy : 0.986328125, acc2: 0.9836001396179199\n",
      "Epoch : 73 completed out of 100, loss : 63.10813522338867, accuracy : 0.9912109375, acc2: 0.9852001070976257\n",
      "Epoch : 74 completed out of 100, loss : 62.11652755737305, accuracy : 0.9892578125, acc2: 0.9857000708580017\n",
      "Epoch : 75 completed out of 100, loss : 72.15603637695312, accuracy : 0.9873046875, acc2: 0.9846001267433167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 76 completed out of 100, loss : 82.93943786621094, accuracy : 0.990234375, acc2: 0.9842001795768738\n",
      "Epoch : 77 completed out of 100, loss : 70.34688568115234, accuracy : 0.986328125, acc2: 0.9808000922203064\n",
      "Epoch : 78 completed out of 100, loss : 61.325401306152344, accuracy : 0.9892578125, acc2: 0.983100175857544\n",
      "Epoch : 79 completed out of 100, loss : 75.35031127929688, accuracy : 0.9873046875, acc2: 0.9851002097129822\n",
      "Epoch : 80 completed out of 100, loss : 57.911041259765625, accuracy : 0.98828125, acc2: 0.9863001704216003\n",
      "Epoch : 81 completed out of 100, loss : 66.95071411132812, accuracy : 0.9892578125, acc2: 0.9862000942230225\n",
      "Epoch : 82 completed out of 100, loss : 82.3820571899414, accuracy : 0.9921875, acc2: 0.9843000769615173\n",
      "Epoch : 83 completed out of 100, loss : 101.98953247070312, accuracy : 0.984375, acc2: 0.9846000671386719\n",
      "Epoch : 84 completed out of 100, loss : 87.40266418457031, accuracy : 0.9873046875, acc2: 0.9853000640869141\n",
      "Epoch : 85 completed out of 100, loss : 62.75894546508789, accuracy : 0.9921875, acc2: 0.9841001033782959\n",
      "Epoch : 86 completed out of 100, loss : 69.04988861083984, accuracy : 0.98828125, acc2: 0.9834001064300537\n",
      "Epoch : 87 completed out of 100, loss : 70.34522247314453, accuracy : 0.9892578125, acc2: 0.9853001832962036\n",
      "Epoch : 88 completed out of 100, loss : 49.129417419433594, accuracy : 0.990234375, acc2: 0.9844001531600952\n",
      "Epoch : 89 completed out of 100, loss : 89.4836196899414, accuracy : 0.98828125, acc2: 0.9850001335144043\n",
      "Epoch : 90 completed out of 100, loss : 66.5281753540039, accuracy : 0.98828125, acc2: 0.9847001433372498\n",
      "Epoch : 91 completed out of 100, loss : 20.506813049316406, accuracy : 0.998046875, acc2: 0.9839001297950745\n",
      "Epoch : 92 completed out of 100, loss : 76.66388702392578, accuracy : 0.9892578125, acc2: 0.9817001223564148\n",
      "Epoch : 93 completed out of 100, loss : 51.098243713378906, accuracy : 0.9912109375, acc2: 0.9832000732421875\n",
      "Epoch : 94 completed out of 100, loss : 73.61885070800781, accuracy : 0.98828125, acc2: 0.9846001267433167\n",
      "Epoch : 95 completed out of 100, loss : 38.96796417236328, accuracy : 0.994140625, acc2: 0.9841001629829407\n",
      "Epoch : 96 completed out of 100, loss : 75.67278289794922, accuracy : 0.9912109375, acc2: 0.9863001108169556\n",
      "Epoch : 97 completed out of 100, loss : 75.13792419433594, accuracy : 0.9892578125, acc2: 0.9840001463890076\n",
      "Epoch : 98 completed out of 100, loss : 26.518863677978516, accuracy : 0.9970703125, acc2: 0.9838001132011414\n",
      "Epoch : 99 completed out of 100, loss : 44.754966735839844, accuracy : 0.9921875, acc2: 0.9841001033782959\n",
      "Accuracy : 0.9841001033782959\n"
     ]
    }
   ],
   "source": [
    "train_neural_network(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
